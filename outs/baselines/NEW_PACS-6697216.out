
--- Run 1/3 ---

Running LoRA with TIES experiment
Test domain: photo
Train domains: ['art_painting', 'sketch', 'cartoon']
Baseline Epoch 1/10, Train Loss: 1.6114, Train Accuracy: 33.33%
Val Loss: 2.0903, Val Accuracy: 21.88%
Baseline Epoch 2/10, Train Loss: 0.5912, Train Accuracy: 100.00%
Val Loss: 2.1012, Val Accuracy: 18.75%
Baseline Epoch 3/10, Train Loss: 0.2126, Train Accuracy: 100.00%
Val Loss: 2.1251, Val Accuracy: 18.75%
Baseline Epoch 4/10, Train Loss: 0.0845, Train Accuracy: 100.00%
Val Loss: 2.1553, Val Accuracy: 18.75%
Baseline Epoch 5/10, Train Loss: 0.0349, Train Accuracy: 100.00%
Val Loss: 2.1845, Val Accuracy: 18.75%
Baseline Epoch 6/10, Train Loss: 0.0149, Train Accuracy: 100.00%
Val Loss: 2.2153, Val Accuracy: 18.75%
Baseline Epoch 7/10, Train Loss: 0.0066, Train Accuracy: 100.00%
Val Loss: 2.2459, Val Accuracy: 21.88%
Baseline Epoch 8/10, Train Loss: 0.0031, Train Accuracy: 100.00%
Val Loss: 2.2775, Val Accuracy: 18.75%
Baseline Epoch 9/10, Train Loss: 0.0016, Train Accuracy: 100.00%
Val Loss: 2.3047, Val Accuracy: 18.75%
Baseline Epoch 10/10, Train Loss: 0.0009, Train Accuracy: 100.00%
Val Loss: 2.3291, Val Accuracy: 18.75%
Baseline Model - Final Test Accuracy: 18.75%

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2928, Train Accuracy: 17.86%
Val Loss: 2.1633, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1931, Train Accuracy: 17.86%
Val Loss: 2.1394, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 2.1166, Train Accuracy: 21.43%
Val Loss: 2.1184, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 2.0386, Train Accuracy: 21.43%
Val Loss: 2.0972, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.9590, Train Accuracy: 21.43%
Val Loss: 2.0749, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.8792, Train Accuracy: 21.43%
Val Loss: 2.0520, Val Accuracy: 14.29%
Epoch 7/10, Train Loss: 1.7985, Train Accuracy: 21.43%
Val Loss: 2.0284, Val Accuracy: 14.29%
Epoch 8/10, Train Loss: 1.7191, Train Accuracy: 28.57%
Val Loss: 2.0044, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.6393, Train Accuracy: 32.14%
Val Loss: 1.9798, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.5588, Train Accuracy: 39.29%
Val Loss: 1.9548, Val Accuracy: 14.29%
Best validation accuracy for art_painting: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
art_painting adapter trained. Validation Accuracy: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: sketch

Training LoRA adapter for domain: sketch
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2668, Train Accuracy: 25.00%
Val Loss: 2.1127, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.1691, Train Accuracy: 21.43%
Val Loss: 2.0638, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.0770, Train Accuracy: 21.43%
Val Loss: 2.0271, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 1.9861, Train Accuracy: 21.43%
Val Loss: 2.0018, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 1.8992, Train Accuracy: 21.43%
Val Loss: 1.9886, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 1.8213, Train Accuracy: 21.43%
Val Loss: 1.9822, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 1.7511, Train Accuracy: 25.00%
Val Loss: 1.9831, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 1.6792, Train Accuracy: 39.29%
Val Loss: 1.9913, Val Accuracy: 28.57%
Epoch 9/10, Train Loss: 1.6130, Train Accuracy: 46.43%
Val Loss: 2.0075, Val Accuracy: 28.57%
Epoch 10/10, Train Loss: 1.5515, Train Accuracy: 50.00%
Val Loss: 2.0316, Val Accuracy: 28.57%
Best validation accuracy for sketch: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
sketch adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6139, Train Accuracy: 10.71%
Val Loss: 2.2562, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 2.4884, Train Accuracy: 14.29%
Val Loss: 2.2434, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 2.4203, Train Accuracy: 10.71%
Val Loss: 2.2349, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 2.3472, Train Accuracy: 10.71%
Val Loss: 2.2281, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 2.2680, Train Accuracy: 10.71%
Val Loss: 2.2254, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 2.1841, Train Accuracy: 10.71%
Val Loss: 2.2257, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 2.1067, Train Accuracy: 10.71%
Val Loss: 2.2230, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 2.0303, Train Accuracy: 10.71%
Val Loss: 2.2190, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.9541, Train Accuracy: 17.86%
Val Loss: 2.2149, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.8802, Train Accuracy: 17.86%
Val Loss: 2.2129, Val Accuracy: 0.00%
Warning: No best state found for domain cartoon. Using the final state.
Best validation accuracy for cartoon: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Training coefficients for adapter merging
