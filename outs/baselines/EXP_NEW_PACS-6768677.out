
Run 1/5
Test domain: cartoon
Training domains: ['art_painting', 'photo', 'sketch']
Training LoRA adapter for domain: art_painting
Epoch 1, Average Loss: 0.8259
Epoch 2, Average Loss: 0.0633
Epoch 3, Average Loss: 0.0159
Epoch 4, Average Loss: 0.0046
Epoch 5, Average Loss: 0.0490
Epoch 6, Average Loss: 0.0642
Epoch 7, Average Loss: 0.0709
Epoch 8, Average Loss: 0.0382
Epoch 9, Average Loss: 0.0228
Epoch 10, Average Loss: 0.0352
Training LoRA adapter for domain: photo
Epoch 1, Average Loss: 0.5139
Epoch 2, Average Loss: 0.0746
Epoch 3, Average Loss: 0.0123
Epoch 4, Average Loss: 0.0245
Epoch 5, Average Loss: 0.0052
Epoch 6, Average Loss: 0.0044
Epoch 7, Average Loss: 0.0122
Epoch 8, Average Loss: 0.0008
Epoch 9, Average Loss: 0.0001
Epoch 10, Average Loss: 0.0001
Training LoRA adapter for domain: sketch
Epoch 1, Average Loss: 1.1788
Epoch 2, Average Loss: 0.4854
Epoch 3, Average Loss: 0.2466
Epoch 4, Average Loss: 0.0617
Epoch 5, Average Loss: 0.0225
Epoch 6, Average Loss: 0.0515
Epoch 7, Average Loss: 0.1040
Epoch 8, Average Loss: 0.0700
Epoch 9, Average Loss: 0.0292
Epoch 10, Average Loss: 0.0901
Training coefficients for weight averaging
Initial coefficients (before normalization):
  art_painting: 1.0000
  photo: 1.0000
  sketch: 1.0000
Initial coefficients (after normalization):
  art_painting: 0.3333
  photo: 0.3333
  sketch: 0.3333
Coefficient Epoch 1, Average Loss: 3.9674
Coefficient Epoch 2, Average Loss: 4.1066
Coefficient Epoch 3, Average Loss: 3.5802
Coefficient Epoch 4, Average Loss: 3.3256
Coefficient Epoch 5, Average Loss: 3.4929
Learned coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]

Run 2/5
Test domain: cartoon
Training domains: ['art_painting', 'photo', 'sketch']
Training LoRA adapter for domain: art_painting
Epoch 1, Average Loss: 0.7715
Epoch 2, Average Loss: 0.1412
Epoch 3, Average Loss: 0.0532
Epoch 4, Average Loss: 0.0412
Epoch 5, Average Loss: 0.0351
Epoch 6, Average Loss: 0.0261
Epoch 7, Average Loss: 0.0769
Epoch 8, Average Loss: 0.0265
Epoch 9, Average Loss: 0.0200
Epoch 10, Average Loss: 0.0063
Training LoRA adapter for domain: photo
Epoch 1, Average Loss: 0.4126
Epoch 2, Average Loss: 0.0745
Epoch 3, Average Loss: 0.0437
Epoch 4, Average Loss: 0.0263
Epoch 5, Average Loss: 0.0019
Epoch 6, Average Loss: 0.0003
Epoch 7, Average Loss: 0.0002
Epoch 8, Average Loss: 0.0001
Epoch 9, Average Loss: 0.0001
Epoch 10, Average Loss: 0.0001
Training LoRA adapter for domain: sketch
Epoch 1, Average Loss: 1.2949
Epoch 2, Average Loss: 0.5739
Epoch 3, Average Loss: 0.3262
Epoch 4, Average Loss: 0.1621
Epoch 5, Average Loss: 0.0654
Epoch 6, Average Loss: 0.0743
Epoch 7, Average Loss: 0.0877
Epoch 8, Average Loss: 0.1570
Epoch 9, Average Loss: 0.0923
Epoch 10, Average Loss: 0.0630
Training coefficients for weight averaging
Initial coefficients (before normalization):
  art_painting: 1.0000
  photo: 1.0000
  sketch: 1.0000
Initial coefficients (after normalization):
  art_painting: 0.3333
  photo: 0.3333
  sketch: 0.3333
Coefficient Epoch 1, Average Loss: 3.9537
Coefficient Epoch 2, Average Loss: 4.2443
Coefficient Epoch 3, Average Loss: 3.7995
Coefficient Epoch 4, Average Loss: 3.8496
Coefficient Epoch 5, Average Loss: 4.2017
Learned coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]

Run 3/5
Test domain: sketch
Training domains: ['art_painting', 'cartoon', 'photo']
Training LoRA adapter for domain: art_painting
Epoch 1, Average Loss: 0.8589
Epoch 2, Average Loss: 0.0911
Epoch 3, Average Loss: 0.0787
Epoch 4, Average Loss: 0.0221
Epoch 5, Average Loss: 0.0114
Epoch 6, Average Loss: 0.0105
Epoch 7, Average Loss: 0.0051
Epoch 8, Average Loss: 0.0364
Epoch 9, Average Loss: 0.0572
Epoch 10, Average Loss: 0.0477
Training LoRA adapter for domain: cartoon
Epoch 1, Average Loss: 0.7337
Epoch 2, Average Loss: 0.1079
Epoch 3, Average Loss: 0.0336
Epoch 4, Average Loss: 0.0042
Epoch 5, Average Loss: 0.0007
Epoch 6, Average Loss: 0.0001
Epoch 7, Average Loss: 0.0001
Epoch 8, Average Loss: 0.0000
Epoch 9, Average Loss: 0.0000
Epoch 10, Average Loss: 0.0000
Training LoRA adapter for domain: photo
Epoch 1, Average Loss: 0.4862
Epoch 2, Average Loss: 0.0404
Epoch 3, Average Loss: 0.0210
Epoch 4, Average Loss: 0.0198
Epoch 5, Average Loss: 0.0044
Epoch 6, Average Loss: 0.0154
Epoch 7, Average Loss: 0.0376
Epoch 8, Average Loss: 0.1989
Epoch 9, Average Loss: 0.1485
Epoch 10, Average Loss: 0.0152
Training coefficients for weight averaging
Initial coefficients (before normalization):
  art_painting: 1.0000
  cartoon: 1.0000
  photo: 1.0000
Initial coefficients (after normalization):
  art_painting: 0.3333
  cartoon: 0.3333
  photo: 0.3333
Coefficient Epoch 1, Average Loss: 5.4786
Coefficient Epoch 2, Average Loss: 4.6954
Coefficient Epoch 3, Average Loss: 5.2286
Coefficient Epoch 4, Average Loss: 4.5401
Coefficient Epoch 5, Average Loss: 4.1470
Learned coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]

Run 4/5
Test domain: cartoon
Training domains: ['art_painting', 'photo', 'sketch']
Training LoRA adapter for domain: art_painting
Epoch 1, Average Loss: 0.8765
Epoch 2, Average Loss: 0.0944
Epoch 3, Average Loss: 0.0154
Epoch 4, Average Loss: 0.0174
Epoch 5, Average Loss: 0.0025
Epoch 6, Average Loss: 0.0003
Epoch 7, Average Loss: 0.0001
Epoch 8, Average Loss: 0.0001
Epoch 9, Average Loss: 0.0001
Epoch 10, Average Loss: 0.0000
Training LoRA adapter for domain: photo
Epoch 1, Average Loss: 0.4692
Epoch 2, Average Loss: 0.0504
Epoch 3, Average Loss: 0.0146
Epoch 4, Average Loss: 0.0025
Epoch 5, Average Loss: 0.0161
Epoch 6, Average Loss: 0.0164
Epoch 7, Average Loss: 0.0031
Epoch 8, Average Loss: 0.0107
Epoch 9, Average Loss: 0.0208
Epoch 10, Average Loss: 0.0629
Training LoRA adapter for domain: sketch
Epoch 1, Average Loss: 1.3233
Epoch 2, Average Loss: 0.5057
Epoch 3, Average Loss: 0.2441
Epoch 4, Average Loss: 0.0948
Epoch 5, Average Loss: 0.1533
Epoch 6, Average Loss: 0.1491
Epoch 7, Average Loss: 0.0763
Epoch 8, Average Loss: 0.0770
Epoch 9, Average Loss: 0.1063
Epoch 10, Average Loss: 0.0378
Training coefficients for weight averaging
Initial coefficients (before normalization):
  art_painting: 1.0000
  photo: 1.0000
  sketch: 1.0000
Initial coefficients (after normalization):
  art_painting: 0.3333
  photo: 0.3333
  sketch: 0.3333
Coefficient Epoch 1, Average Loss: 5.5610
Coefficient Epoch 2, Average Loss: 5.2085
Coefficient Epoch 3, Average Loss: 5.2029
Coefficient Epoch 4, Average Loss: 5.1471
Coefficient Epoch 5, Average Loss: 5.0747
Learned coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]

Run 5/5
Test domain: sketch
Training domains: ['art_painting', 'cartoon', 'photo']
Training LoRA adapter for domain: art_painting
Epoch 1, Average Loss: 0.8036
Epoch 2, Average Loss: 0.1124
Epoch 3, Average Loss: 0.0286
Epoch 4, Average Loss: 0.0290
Epoch 5, Average Loss: 0.0442
Epoch 6, Average Loss: 0.0066
Epoch 7, Average Loss: 0.0004
Epoch 8, Average Loss: 0.0001
Epoch 9, Average Loss: 0.0001
Epoch 10, Average Loss: 0.0001
Training LoRA adapter for domain: cartoon
Epoch 1, Average Loss: 0.9061
Epoch 2, Average Loss: 0.1015
Epoch 3, Average Loss: 0.0645
Epoch 4, Average Loss: 0.0408
Epoch 5, Average Loss: 0.0133
Epoch 6, Average Loss: 0.0061
Epoch 7, Average Loss: 0.0009
Epoch 8, Average Loss: 0.0002
Epoch 9, Average Loss: 0.0001
Epoch 10, Average Loss: 0.0001
Training LoRA adapter for domain: photo
Epoch 1, Average Loss: 0.4840
Epoch 2, Average Loss: 0.0527
Epoch 3, Average Loss: 0.0142
Epoch 4, Average Loss: 0.0019
Epoch 5, Average Loss: 0.0096
Epoch 6, Average Loss: 0.0287
Epoch 7, Average Loss: 0.0209
Epoch 8, Average Loss: 0.0083
Epoch 9, Average Loss: 0.0076
Epoch 10, Average Loss: 0.0006
Training coefficients for weight averaging
Initial coefficients (before normalization):
  art_painting: 1.0000
  cartoon: 1.0000
  photo: 1.0000
Initial coefficients (after normalization):
  art_painting: 0.3333
  cartoon: 0.3333
  photo: 0.3333
Coefficient Epoch 1, Average Loss: 4.1143
Coefficient Epoch 2, Average Loss: 3.9708
Coefficient Epoch 3, Average Loss: 4.1341
Coefficient Epoch 4, Average Loss: 3.9267
Coefficient Epoch 5, Average Loss: 3.9642
Learned coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]

Run 1 Results:
Test Domain: cartoon
Coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]
LoRA Adapters:
  art_painting: 72 parameters
  photo: 72 parameters
  sketch: 72 parameters

Run 2 Results:
Test Domain: cartoon
Coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]
LoRA Adapters:
  art_painting: 72 parameters
  photo: 72 parameters
  sketch: 72 parameters

Run 3 Results:
Test Domain: sketch
Coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]
LoRA Adapters:
  art_painting: 72 parameters
  cartoon: 72 parameters
  photo: 72 parameters

Run 4 Results:
Test Domain: cartoon
Coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]
LoRA Adapters:
  art_painting: 72 parameters
  photo: 72 parameters
  sketch: 72 parameters

Run 5 Results:
Test Domain: sketch
Coefficients: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]
LoRA Adapters:
  art_painting: 72 parameters
  cartoon: 72 parameters
  photo: 72 parameters
