
--- Run 1/3 ---

Running LoRA with TIES experiment
Test domain: sketch
Train domains: ['photo', 'cartoon', 'art_painting']
Baseline Epoch 1/10, Train Loss: 1.4914, Train Accuracy: 33.33%
Val Loss: 2.2648, Val Accuracy: 12.50%
Baseline Epoch 2/10, Train Loss: 0.8927, Train Accuracy: 66.67%
Val Loss: 2.4858, Val Accuracy: 12.50%
Baseline Epoch 3/10, Train Loss: 0.4985, Train Accuracy: 100.00%
Val Loss: 2.7342, Val Accuracy: 18.75%
Baseline Epoch 4/10, Train Loss: 0.2737, Train Accuracy: 100.00%
Val Loss: 2.9774, Val Accuracy: 18.75%
Baseline Epoch 5/10, Train Loss: 0.1469, Train Accuracy: 100.00%
Val Loss: 3.1821, Val Accuracy: 18.75%
Baseline Epoch 6/10, Train Loss: 0.0775, Train Accuracy: 100.00%
Val Loss: 3.3527, Val Accuracy: 18.75%
Baseline Epoch 7/10, Train Loss: 0.0426, Train Accuracy: 100.00%
Val Loss: 3.5020, Val Accuracy: 18.75%
Baseline Epoch 8/10, Train Loss: 0.0237, Train Accuracy: 100.00%
Val Loss: 3.6350, Val Accuracy: 18.75%
Baseline Epoch 9/10, Train Loss: 0.0132, Train Accuracy: 100.00%
Val Loss: 3.7537, Val Accuracy: 18.75%
Baseline Epoch 10/10, Train Loss: 0.0075, Train Accuracy: 100.00%
Val Loss: 3.8597, Val Accuracy: 18.75%
Baseline Model - Final Test Accuracy: 18.75%

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 1.9158, Train Accuracy: 28.57%
Val Loss: 2.6368, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 1.8702, Train Accuracy: 28.57%
Val Loss: 2.6163, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 1.8225, Train Accuracy: 32.14%
Val Loss: 2.5949, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 1.7711, Train Accuracy: 35.71%
Val Loss: 2.5734, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 1.7235, Train Accuracy: 39.29%
Val Loss: 2.5544, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 1.6727, Train Accuracy: 39.29%
Val Loss: 2.5356, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 1.6239, Train Accuracy: 42.86%
Val Loss: 2.5160, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 1.5734, Train Accuracy: 42.86%
Val Loss: 2.4959, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.5223, Train Accuracy: 42.86%
Val Loss: 2.4758, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.4712, Train Accuracy: 46.43%
Val Loss: 2.4555, Val Accuracy: 0.00%
Warning: No best state found for domain photo. Using the final state.
Best validation accuracy for photo: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
photo adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6305, Train Accuracy: 7.14%
Val Loss: 2.0953, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.5277, Train Accuracy: 7.14%
Val Loss: 2.0542, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.4690, Train Accuracy: 3.57%
Val Loss: 2.0359, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 2.4032, Train Accuracy: 7.14%
Val Loss: 2.0294, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 2.3345, Train Accuracy: 7.14%
Val Loss: 2.0307, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 2.2612, Train Accuracy: 7.14%
Val Loss: 2.0400, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 2.1805, Train Accuracy: 10.71%
Val Loss: 2.0554, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 2.0982, Train Accuracy: 14.29%
Val Loss: 2.0744, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 2.0179, Train Accuracy: 14.29%
Val Loss: 2.0962, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.9425, Train Accuracy: 21.43%
Val Loss: 2.1145, Val Accuracy: 14.29%
Best validation accuracy for cartoon: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.3176, Train Accuracy: 14.29%
Val Loss: 2.0843, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.2144, Train Accuracy: 17.86%
Val Loss: 2.0851, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.1329, Train Accuracy: 17.86%
Val Loss: 2.0854, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 2.0513, Train Accuracy: 17.86%
Val Loss: 2.0865, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 1.9688, Train Accuracy: 17.86%
Val Loss: 2.0884, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 1.8856, Train Accuracy: 25.00%
Val Loss: 2.0911, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 1.8013, Train Accuracy: 28.57%
Val Loss: 2.0947, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 1.7186, Train Accuracy: 32.14%
Val Loss: 2.0991, Val Accuracy: 28.57%
Epoch 9/10, Train Loss: 1.6339, Train Accuracy: 32.14%
Val Loss: 2.1045, Val Accuracy: 28.57%
Epoch 10/10, Train Loss: 1.5524, Train Accuracy: 39.29%
Val Loss: 2.1104, Val Accuracy: 14.29%
Best validation accuracy for art_painting: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
art_painting adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Training coefficients for adapter merging
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 1, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 2, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([1.8723e-10, 1.8723e-10, 1.8723e-10], device='cuda:0')
Epoch 3, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 4, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 5, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 6, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 7, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 8, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 9, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([1.8723e-10, 1.8723e-10, 1.8723e-10], device='cuda:0')
Epoch 10, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Best coefficient accuracy: 33.33%
Final best coefficients: [0.33333334 0.33333334 0.33333334]

Merged model with TIES - Test Loss: 1.9528, Test Accuracy: 18.75%

--- Run 2/3 ---

Running LoRA with TIES experiment
Test domain: sketch
Train domains: ['photo', 'cartoon', 'art_painting']
Baseline Epoch 1/10, Train Loss: 1.4914, Train Accuracy: 33.33%
Val Loss: 2.2648, Val Accuracy: 12.50%
Baseline Epoch 2/10, Train Loss: 0.8927, Train Accuracy: 66.67%
Val Loss: 2.4858, Val Accuracy: 12.50%
Baseline Epoch 3/10, Train Loss: 0.4985, Train Accuracy: 100.00%
Val Loss: 2.7342, Val Accuracy: 18.75%
Baseline Epoch 4/10, Train Loss: 0.2737, Train Accuracy: 100.00%
Val Loss: 2.9774, Val Accuracy: 18.75%
Baseline Epoch 5/10, Train Loss: 0.1469, Train Accuracy: 100.00%
Val Loss: 3.1821, Val Accuracy: 18.75%
Baseline Epoch 6/10, Train Loss: 0.0775, Train Accuracy: 100.00%
Val Loss: 3.3527, Val Accuracy: 18.75%
Baseline Epoch 7/10, Train Loss: 0.0426, Train Accuracy: 100.00%
Val Loss: 3.5020, Val Accuracy: 18.75%
Baseline Epoch 8/10, Train Loss: 0.0237, Train Accuracy: 100.00%
Val Loss: 3.6350, Val Accuracy: 18.75%
Baseline Epoch 9/10, Train Loss: 0.0132, Train Accuracy: 100.00%
Val Loss: 3.7537, Val Accuracy: 18.75%
Baseline Epoch 10/10, Train Loss: 0.0075, Train Accuracy: 100.00%
Val Loss: 3.8597, Val Accuracy: 18.75%
Baseline Model - Final Test Accuracy: 18.75%

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 1.9158, Train Accuracy: 28.57%
Val Loss: 2.6368, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 1.8702, Train Accuracy: 28.57%
Val Loss: 2.6163, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 1.8225, Train Accuracy: 32.14%
Val Loss: 2.5949, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 1.7711, Train Accuracy: 35.71%
Val Loss: 2.5734, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 1.7235, Train Accuracy: 39.29%
Val Loss: 2.5544, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 1.6727, Train Accuracy: 39.29%
Val Loss: 2.5356, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 1.6239, Train Accuracy: 42.86%
Val Loss: 2.5160, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 1.5734, Train Accuracy: 42.86%
Val Loss: 2.4959, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.5223, Train Accuracy: 42.86%
Val Loss: 2.4758, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.4712, Train Accuracy: 46.43%
Val Loss: 2.4555, Val Accuracy: 0.00%
Warning: No best state found for domain photo. Using the final state.
Best validation accuracy for photo: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
photo adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6305, Train Accuracy: 7.14%
Val Loss: 2.0953, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.5277, Train Accuracy: 7.14%
Val Loss: 2.0542, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.4690, Train Accuracy: 3.57%
Val Loss: 2.0359, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 2.4032, Train Accuracy: 7.14%
Val Loss: 2.0294, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 2.3345, Train Accuracy: 7.14%
Val Loss: 2.0307, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 2.2612, Train Accuracy: 7.14%
Val Loss: 2.0400, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 2.1805, Train Accuracy: 10.71%
Val Loss: 2.0554, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 2.0982, Train Accuracy: 14.29%
Val Loss: 2.0744, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 2.0179, Train Accuracy: 14.29%
Val Loss: 2.0962, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.9425, Train Accuracy: 21.43%
Val Loss: 2.1145, Val Accuracy: 14.29%
Best validation accuracy for cartoon: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.3176, Train Accuracy: 14.29%
Val Loss: 2.0843, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.2144, Train Accuracy: 17.86%
Val Loss: 2.0851, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.1329, Train Accuracy: 17.86%
Val Loss: 2.0854, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 2.0513, Train Accuracy: 17.86%
Val Loss: 2.0865, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 1.9688, Train Accuracy: 17.86%
Val Loss: 2.0884, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 1.8856, Train Accuracy: 25.00%
Val Loss: 2.0911, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 1.8013, Train Accuracy: 28.57%
Val Loss: 2.0947, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 1.7186, Train Accuracy: 32.14%
Val Loss: 2.0991, Val Accuracy: 28.57%
Epoch 9/10, Train Loss: 1.6339, Train Accuracy: 32.14%
Val Loss: 2.1045, Val Accuracy: 28.57%
Epoch 10/10, Train Loss: 1.5524, Train Accuracy: 39.29%
Val Loss: 2.1104, Val Accuracy: 14.29%
Best validation accuracy for art_painting: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
art_painting adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Training coefficients for adapter merging
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Coefficient gradients: tensor([-4.3366e-10, -4.3366e-10, -4.3366e-10], device='cuda:0')
Epoch 1, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([1.8722e-10, 1.8722e-10, 1.8722e-10], device='cuda:0')
Epoch 2, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.3366e-10, -4.3366e-10, -4.3366e-10], device='cuda:0')
Epoch 3, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 4, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 5, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 6, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([1.8722e-10, 1.8722e-10, 1.8722e-10], device='cuda:0')
Epoch 7, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.3366e-10, -4.3366e-10, -4.3366e-10], device='cuda:0')
Epoch 8, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0811e-10, 8.0811e-10, 8.0811e-10], device='cuda:0')
Epoch 9, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0810e-10, 8.0810e-10, 8.0810e-10], device='cuda:0')
Epoch 10, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Best coefficient accuracy: 33.33%
Final best coefficients: [0.33333334 0.33333334 0.33333334]

Merged model with TIES - Test Loss: 1.9528, Test Accuracy: 18.75%

--- Run 3/3 ---

Running LoRA with TIES experiment
Test domain: sketch
Train domains: ['photo', 'cartoon', 'art_painting']
Baseline Epoch 1/10, Train Loss: 1.4914, Train Accuracy: 33.33%
Val Loss: 2.2648, Val Accuracy: 12.50%
Baseline Epoch 2/10, Train Loss: 0.8927, Train Accuracy: 66.67%
Val Loss: 2.4858, Val Accuracy: 12.50%
Baseline Epoch 3/10, Train Loss: 0.4985, Train Accuracy: 100.00%
Val Loss: 2.7342, Val Accuracy: 18.75%
Baseline Epoch 4/10, Train Loss: 0.2737, Train Accuracy: 100.00%
Val Loss: 2.9774, Val Accuracy: 18.75%
Baseline Epoch 5/10, Train Loss: 0.1469, Train Accuracy: 100.00%
Val Loss: 3.1821, Val Accuracy: 18.75%
Baseline Epoch 6/10, Train Loss: 0.0775, Train Accuracy: 100.00%
Val Loss: 3.3527, Val Accuracy: 18.75%
Baseline Epoch 7/10, Train Loss: 0.0426, Train Accuracy: 100.00%
Val Loss: 3.5020, Val Accuracy: 18.75%
Baseline Epoch 8/10, Train Loss: 0.0237, Train Accuracy: 100.00%
Val Loss: 3.6350, Val Accuracy: 18.75%
Baseline Epoch 9/10, Train Loss: 0.0132, Train Accuracy: 100.00%
Val Loss: 3.7537, Val Accuracy: 18.75%
Baseline Epoch 10/10, Train Loss: 0.0075, Train Accuracy: 100.00%
Val Loss: 3.8597, Val Accuracy: 18.75%
Baseline Model - Final Test Accuracy: 18.75%

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 1.9158, Train Accuracy: 28.57%
Val Loss: 2.6368, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 1.8702, Train Accuracy: 28.57%
Val Loss: 2.6163, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 1.8225, Train Accuracy: 32.14%
Val Loss: 2.5949, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 1.7711, Train Accuracy: 35.71%
Val Loss: 2.5734, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 1.7235, Train Accuracy: 39.29%
Val Loss: 2.5544, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 1.6727, Train Accuracy: 39.29%
Val Loss: 2.5356, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 1.6239, Train Accuracy: 42.86%
Val Loss: 2.5160, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 1.5734, Train Accuracy: 42.86%
Val Loss: 2.4959, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.5223, Train Accuracy: 42.86%
Val Loss: 2.4758, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.4712, Train Accuracy: 46.43%
Val Loss: 2.4555, Val Accuracy: 0.00%
Warning: No best state found for domain photo. Using the final state.
Best validation accuracy for photo: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
photo adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6305, Train Accuracy: 7.14%
Val Loss: 2.0953, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.5277, Train Accuracy: 7.14%
Val Loss: 2.0542, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.4690, Train Accuracy: 3.57%
Val Loss: 2.0359, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 2.4032, Train Accuracy: 7.14%
Val Loss: 2.0294, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 2.3345, Train Accuracy: 7.14%
Val Loss: 2.0307, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 2.2612, Train Accuracy: 7.14%
Val Loss: 2.0400, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 2.1805, Train Accuracy: 10.71%
Val Loss: 2.0554, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 2.0982, Train Accuracy: 14.29%
Val Loss: 2.0744, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 2.0179, Train Accuracy: 14.29%
Val Loss: 2.0962, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.9425, Train Accuracy: 21.43%
Val Loss: 2.1145, Val Accuracy: 14.29%
Best validation accuracy for cartoon: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.3176, Train Accuracy: 14.29%
Val Loss: 2.0843, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.2144, Train Accuracy: 17.86%
Val Loss: 2.0851, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.1329, Train Accuracy: 17.86%
Val Loss: 2.0854, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 2.0513, Train Accuracy: 17.86%
Val Loss: 2.0865, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 1.9688, Train Accuracy: 17.86%
Val Loss: 2.0884, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 1.8856, Train Accuracy: 25.00%
Val Loss: 2.0911, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 1.8013, Train Accuracy: 28.57%
Val Loss: 2.0947, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 1.7186, Train Accuracy: 32.14%
Val Loss: 2.0991, Val Accuracy: 28.57%
Epoch 9/10, Train Loss: 1.6339, Train Accuracy: 32.14%
Val Loss: 2.1045, Val Accuracy: 28.57%
Epoch 10/10, Train Loss: 1.5524, Train Accuracy: 39.29%
Val Loss: 2.1104, Val Accuracy: 14.29%
Best validation accuracy for art_painting: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
art_painting adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Training coefficients for adapter merging
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Coefficient gradients: tensor([-4.3363e-10, -4.3363e-10, -4.3363e-10], device='cuda:0')
Epoch 1, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([1.8725e-10, 1.8725e-10, 1.8725e-10], device='cuda:0')
Epoch 2, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([8.0813e-10, 8.0813e-10, 8.0813e-10], device='cuda:0')
Epoch 3, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.3363e-10, -4.3363e-10, -4.3363e-10], device='cuda:0')
Epoch 4, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.3363e-10, -4.3363e-10, -4.3363e-10], device='cuda:0')
Epoch 5, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.3363e-10, -4.3363e-10, -4.3363e-10], device='cuda:0')
Epoch 6, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([1.8725e-10, 1.8725e-10, 1.8725e-10], device='cuda:0')
Epoch 7, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.3363e-10, -4.3363e-10, -4.3363e-10], device='cuda:0')
Epoch 8, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.3363e-10, -4.3363e-10, -4.3363e-10], device='cuda:0')
Epoch 9, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.3363e-10, -4.3363e-10, -4.3363e-10], device='cuda:0')
Epoch 10, Loss: 1.4887, Accuracy: 33.33%
Coefficients: [0.33333334 0.33333334 0.33333334]
Best coefficient accuracy: 33.33%
Final best coefficients: [0.33333334 0.33333334 0.33333334]

Merged model with TIES - Test Loss: 1.9528, Test Accuracy: 18.75%

Summary of All Runs:
Baseline Model Accuracy: 18.75% ± 0.00%
Merged Model Accuracy: 18.75% ± 0.00%
Average Coefficients:
  photo: 0.3333 ± 0.0000
  cartoon: 0.3333 ± 0.0000
  art_painting: 0.3333 ± 0.0000
