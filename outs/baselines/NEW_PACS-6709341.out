
--- Run 1/3 ---

Running LoRA with TIES experiment
Test domain: sketch
Train domains: ['art_painting', 'photo', 'cartoon']
Baseline Epoch 1/10, Train Loss: 1.4914, Train Accuracy: 33.33%
Val Loss: 2.2648, Val Accuracy: 12.50%
Baseline Epoch 2/10, Train Loss: 0.8927, Train Accuracy: 66.67%
Val Loss: 2.4858, Val Accuracy: 12.50%
Baseline Epoch 3/10, Train Loss: 0.4985, Train Accuracy: 100.00%
Val Loss: 2.7342, Val Accuracy: 18.75%
Baseline Epoch 4/10, Train Loss: 0.2737, Train Accuracy: 100.00%
Val Loss: 2.9774, Val Accuracy: 18.75%
Baseline Epoch 5/10, Train Loss: 0.1469, Train Accuracy: 100.00%
Val Loss: 3.1821, Val Accuracy: 18.75%
Baseline Epoch 6/10, Train Loss: 0.0775, Train Accuracy: 100.00%
Val Loss: 3.3527, Val Accuracy: 18.75%
Baseline Epoch 7/10, Train Loss: 0.0426, Train Accuracy: 100.00%
Val Loss: 3.5020, Val Accuracy: 18.75%
Baseline Epoch 8/10, Train Loss: 0.0237, Train Accuracy: 100.00%
Val Loss: 3.6350, Val Accuracy: 18.75%
Baseline Epoch 9/10, Train Loss: 0.0132, Train Accuracy: 100.00%
Val Loss: 3.7537, Val Accuracy: 18.75%
Baseline Epoch 10/10, Train Loss: 0.0075, Train Accuracy: 100.00%
Val Loss: 3.8597, Val Accuracy: 18.75%
Baseline Model - Final Test Accuracy: 18.75%

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2928, Train Accuracy: 17.86%
Val Loss: 2.1633, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1931, Train Accuracy: 17.86%
Val Loss: 2.1394, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 2.1166, Train Accuracy: 21.43%
Val Loss: 2.1184, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 2.0386, Train Accuracy: 21.43%
Val Loss: 2.0972, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.9590, Train Accuracy: 21.43%
Val Loss: 2.0749, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.8792, Train Accuracy: 21.43%
Val Loss: 2.0520, Val Accuracy: 14.29%
Epoch 7/10, Train Loss: 1.7985, Train Accuracy: 21.43%
Val Loss: 2.0284, Val Accuracy: 14.29%
Epoch 8/10, Train Loss: 1.7191, Train Accuracy: 28.57%
Val Loss: 2.0044, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.6393, Train Accuracy: 32.14%
Val Loss: 1.9798, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.5588, Train Accuracy: 39.29%
Val Loss: 1.9548, Val Accuracy: 14.29%
Best validation accuracy for art_painting: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
art_painting adapter trained. Validation Accuracy: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.0397, Train Accuracy: 21.43%
Val Loss: 2.1441, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 1.9932, Train Accuracy: 21.43%
Val Loss: 2.1268, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 1.9456, Train Accuracy: 25.00%
Val Loss: 2.1093, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 1.8937, Train Accuracy: 28.57%
Val Loss: 2.0921, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 1.8496, Train Accuracy: 32.14%
Val Loss: 2.0762, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 1.7988, Train Accuracy: 35.71%
Val Loss: 2.0611, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 1.7511, Train Accuracy: 35.71%
Val Loss: 2.0455, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 1.7042, Train Accuracy: 39.29%
Val Loss: 2.0295, Val Accuracy: 28.57%
Epoch 9/10, Train Loss: 1.6539, Train Accuracy: 39.29%
Val Loss: 2.0131, Val Accuracy: 28.57%
Epoch 10/10, Train Loss: 1.6026, Train Accuracy: 46.43%
Val Loss: 1.9962, Val Accuracy: 28.57%
Best validation accuracy for photo: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
photo adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6139, Train Accuracy: 10.71%
Val Loss: 2.2562, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 2.4884, Train Accuracy: 14.29%
Val Loss: 2.2434, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 2.4203, Train Accuracy: 10.71%
Val Loss: 2.2349, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 2.3472, Train Accuracy: 10.71%
Val Loss: 2.2281, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 2.2680, Train Accuracy: 10.71%
Val Loss: 2.2254, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 2.1841, Train Accuracy: 10.71%
Val Loss: 2.2257, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 2.1067, Train Accuracy: 10.71%
Val Loss: 2.2230, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 2.0303, Train Accuracy: 10.71%
Val Loss: 2.2190, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.9541, Train Accuracy: 17.86%
Val Loss: 2.2149, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.8802, Train Accuracy: 17.86%
Val Loss: 2.2129, Val Accuracy: 0.00%
Warning: No best state found for domain cartoon. Using the final state.
Best validation accuracy for cartoon: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Evaluating individual LoRA adapters on the test domain:
Created LoRA model: <class 'peft.peft_model.PeftModel'>
art_painting adapter - Test Loss: 2.2703, Test Accuracy: 21.88%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
photo adapter - Test Loss: 2.2324, Test Accuracy: 21.88%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
cartoon adapter - Test Loss: 2.1003, Test Accuracy: 18.75%

Training coefficients for adapter merging
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Coefficient gradients: tensor([-1.4374e-09, -1.4374e-09, -1.4374e-09], device='cuda:0')
Epoch 1, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.33276686 0.33233485 0.33489832]
Coefficient gradients: tensor([-1.6372e-09,  3.0645e-09,  1.7112e-09], device='cuda:0')
Epoch 2, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.3720653  0.30181938 0.3261153 ]
Coefficient gradients: tensor([ 4.7755e-09, -3.3787e-09, -1.3969e-09], device='cuda:0')
Epoch 3, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.34990644 0.31593183 0.33416173]
Coefficient gradients: tensor([ 2.0127e-10, -7.4126e-10,  5.3999e-10], device='cuda:0')
Epoch 4, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.33245602 0.33005044 0.33749354]
Coefficient gradients: tensor([-3.5487e-09,  3.3696e-09,  1.7909e-10], device='cuda:0')
Epoch 5, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.34326488 0.31889954 0.3378356 ]
Coefficient gradients: tensor([ 3.5189e-09,  1.6663e-09, -2.0467e-09], device='cuda:0')
Epoch 6, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.33369958 0.30754307 0.35875738]
Coefficient gradients: tensor([ 3.6366e-09, -3.2293e-09,  2.7313e-09], device='cuda:0')
Epoch 7, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.3178954  0.31957224 0.36253232]
Coefficient gradients: tensor([ 3.6072e-09, -1.1452e-09, -5.6005e-09], device='cuda:0')
Epoch 8, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.2795186  0.33227053 0.3882108 ]
Coefficient gradients: tensor([-7.7273e-09, -9.7344e-09, -1.1167e-08], device='cuda:0')
Epoch 9, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.24689388 0.3333013  0.4198048 ]
Coefficient gradients: tensor([ 1.1242e-09, -2.3394e-10, -8.9031e-10], device='cuda:0')
Epoch 10, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.21898934 0.33447617 0.4465345 ]
Best coefficient accuracy: 33.33%
Final best coefficients: [0.33276686 0.33233485 0.33489832]

Merged model with TIES - Test Loss: 1.9162, Test Accuracy: 15.62%

--- Run 2/3 ---

Running LoRA with TIES experiment
Test domain: sketch
Train domains: ['art_painting', 'photo', 'cartoon']
Baseline Epoch 1/10, Train Loss: 1.4914, Train Accuracy: 33.33%
Val Loss: 2.2648, Val Accuracy: 12.50%
Baseline Epoch 2/10, Train Loss: 0.8927, Train Accuracy: 66.67%
Val Loss: 2.4858, Val Accuracy: 12.50%
Baseline Epoch 3/10, Train Loss: 0.4985, Train Accuracy: 100.00%
Val Loss: 2.7342, Val Accuracy: 18.75%
Baseline Epoch 4/10, Train Loss: 0.2737, Train Accuracy: 100.00%
Val Loss: 2.9774, Val Accuracy: 18.75%
Baseline Epoch 5/10, Train Loss: 0.1469, Train Accuracy: 100.00%
Val Loss: 3.1821, Val Accuracy: 18.75%
Baseline Epoch 6/10, Train Loss: 0.0775, Train Accuracy: 100.00%
Val Loss: 3.3527, Val Accuracy: 18.75%
Baseline Epoch 7/10, Train Loss: 0.0426, Train Accuracy: 100.00%
Val Loss: 3.5020, Val Accuracy: 18.75%
Baseline Epoch 8/10, Train Loss: 0.0237, Train Accuracy: 100.00%
Val Loss: 3.6350, Val Accuracy: 18.75%
Baseline Epoch 9/10, Train Loss: 0.0132, Train Accuracy: 100.00%
Val Loss: 3.7537, Val Accuracy: 18.75%
Baseline Epoch 10/10, Train Loss: 0.0075, Train Accuracy: 100.00%
Val Loss: 3.8597, Val Accuracy: 18.75%
Baseline Model - Final Test Accuracy: 18.75%

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2928, Train Accuracy: 17.86%
Val Loss: 2.1633, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1931, Train Accuracy: 17.86%
Val Loss: 2.1394, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 2.1166, Train Accuracy: 21.43%
Val Loss: 2.1184, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 2.0386, Train Accuracy: 21.43%
Val Loss: 2.0972, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.9590, Train Accuracy: 21.43%
Val Loss: 2.0749, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.8792, Train Accuracy: 21.43%
Val Loss: 2.0520, Val Accuracy: 14.29%
Epoch 7/10, Train Loss: 1.7985, Train Accuracy: 21.43%
Val Loss: 2.0284, Val Accuracy: 14.29%
Epoch 8/10, Train Loss: 1.7191, Train Accuracy: 28.57%
Val Loss: 2.0044, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.6393, Train Accuracy: 32.14%
Val Loss: 1.9798, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.5588, Train Accuracy: 39.29%
Val Loss: 1.9548, Val Accuracy: 14.29%
Best validation accuracy for art_painting: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
art_painting adapter trained. Validation Accuracy: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.0397, Train Accuracy: 21.43%
Val Loss: 2.1441, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 1.9932, Train Accuracy: 21.43%
Val Loss: 2.1268, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 1.9456, Train Accuracy: 25.00%
Val Loss: 2.1093, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 1.8937, Train Accuracy: 28.57%
Val Loss: 2.0921, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 1.8496, Train Accuracy: 32.14%
Val Loss: 2.0762, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 1.7988, Train Accuracy: 35.71%
Val Loss: 2.0611, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 1.7511, Train Accuracy: 35.71%
Val Loss: 2.0455, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 1.7042, Train Accuracy: 39.29%
Val Loss: 2.0295, Val Accuracy: 28.57%
Epoch 9/10, Train Loss: 1.6539, Train Accuracy: 39.29%
Val Loss: 2.0131, Val Accuracy: 28.57%
Epoch 10/10, Train Loss: 1.6026, Train Accuracy: 46.43%
Val Loss: 1.9962, Val Accuracy: 28.57%
Best validation accuracy for photo: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
photo adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6139, Train Accuracy: 10.71%
Val Loss: 2.2562, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 2.4884, Train Accuracy: 14.29%
Val Loss: 2.2434, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 2.4203, Train Accuracy: 10.71%
Val Loss: 2.2349, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 2.3472, Train Accuracy: 10.71%
Val Loss: 2.2281, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 2.2680, Train Accuracy: 10.71%
Val Loss: 2.2254, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 2.1841, Train Accuracy: 10.71%
Val Loss: 2.2257, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 2.1067, Train Accuracy: 10.71%
Val Loss: 2.2230, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 2.0303, Train Accuracy: 10.71%
Val Loss: 2.2190, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.9541, Train Accuracy: 17.86%
Val Loss: 2.2149, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.8802, Train Accuracy: 17.86%
Val Loss: 2.2129, Val Accuracy: 0.00%
Warning: No best state found for domain cartoon. Using the final state.
Best validation accuracy for cartoon: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Evaluating individual LoRA adapters on the test domain:
Created LoRA model: <class 'peft.peft_model.PeftModel'>
art_painting adapter - Test Loss: 2.2703, Test Accuracy: 21.88%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
photo adapter - Test Loss: 2.2324, Test Accuracy: 21.88%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
cartoon adapter - Test Loss: 2.1003, Test Accuracy: 18.75%

Training coefficients for adapter merging
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Coefficient gradients: tensor([1.0462e-09, 1.0462e-09, 1.0462e-09], device='cuda:0')
Epoch 1, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.33276686 0.33233485 0.33489832]
Coefficient gradients: tensor([ 2.8909e-09, -1.9268e-10,  4.4033e-10], device='cuda:0')
Epoch 2, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.3063853  0.3484499  0.34516484]
Coefficient gradients: tensor([6.7135e-09, 6.9533e-09, 1.1824e-08], device='cuda:0')
Epoch 3, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.30325568 0.3653823  0.331362  ]
Coefficient gradients: tensor([ 1.1256e-09,  3.8359e-11, -1.1639e-09], device='cuda:0')
Epoch 4, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.293961   0.37606516 0.32997385]
Coefficient gradients: tensor([ 2.3748e-09, -1.2530e-09, -1.1218e-09], device='cuda:0')
Epoch 5, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.27535075 0.39217976 0.33246946]
Coefficient gradients: tensor([ 3.3952e-09, -7.1456e-09,  6.1188e-10], device='cuda:0')
Epoch 6, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.23735052 0.4409767  0.32167274]
Coefficient gradients: tensor([-8.3789e-10, -7.9365e-10, -1.5070e-09], device='cuda:0')
Epoch 7, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.21007657 0.48078027 0.3091431 ]
Coefficient gradients: tensor([-8.4642e-09, -2.0546e-08, -7.0696e-09], device='cuda:0')
Epoch 8, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.17886172 0.5417367  0.2794016 ]
Coefficient gradients: tensor([ 1.1684e-09, -8.8838e-10,  7.0252e-10], device='cuda:0')
Epoch 9, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.15380408 0.58825874 0.2579372 ]
Coefficient gradients: tensor([-1.6499e-09,  5.5292e-09,  1.4153e-09], device='cuda:0')
Epoch 10, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.1415882  0.61780834 0.24060348]
Best coefficient accuracy: 33.33%
Final best coefficients: [0.33276686 0.33233485 0.33489832]

Merged model with TIES - Test Loss: 1.9162, Test Accuracy: 15.62%

--- Run 3/3 ---

Running LoRA with TIES experiment
Test domain: sketch
Train domains: ['art_painting', 'photo', 'cartoon']
Baseline Epoch 1/10, Train Loss: 1.4914, Train Accuracy: 33.33%
Val Loss: 2.2648, Val Accuracy: 12.50%
Baseline Epoch 2/10, Train Loss: 0.8927, Train Accuracy: 66.67%
Val Loss: 2.4858, Val Accuracy: 12.50%
Baseline Epoch 3/10, Train Loss: 0.4985, Train Accuracy: 100.00%
Val Loss: 2.7342, Val Accuracy: 18.75%
Baseline Epoch 4/10, Train Loss: 0.2737, Train Accuracy: 100.00%
Val Loss: 2.9774, Val Accuracy: 18.75%
Baseline Epoch 5/10, Train Loss: 0.1469, Train Accuracy: 100.00%
Val Loss: 3.1821, Val Accuracy: 18.75%
Baseline Epoch 6/10, Train Loss: 0.0775, Train Accuracy: 100.00%
Val Loss: 3.3527, Val Accuracy: 18.75%
Baseline Epoch 7/10, Train Loss: 0.0426, Train Accuracy: 100.00%
Val Loss: 3.5020, Val Accuracy: 18.75%
Baseline Epoch 8/10, Train Loss: 0.0237, Train Accuracy: 100.00%
Val Loss: 3.6350, Val Accuracy: 18.75%
Baseline Epoch 9/10, Train Loss: 0.0132, Train Accuracy: 100.00%
Val Loss: 3.7537, Val Accuracy: 18.75%
Baseline Epoch 10/10, Train Loss: 0.0075, Train Accuracy: 100.00%
Val Loss: 3.8597, Val Accuracy: 18.75%
Baseline Model - Final Test Accuracy: 18.75%

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2928, Train Accuracy: 17.86%
Val Loss: 2.1633, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1931, Train Accuracy: 17.86%
Val Loss: 2.1394, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 2.1166, Train Accuracy: 21.43%
Val Loss: 2.1184, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 2.0386, Train Accuracy: 21.43%
Val Loss: 2.0972, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.9590, Train Accuracy: 21.43%
Val Loss: 2.0749, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.8792, Train Accuracy: 21.43%
Val Loss: 2.0520, Val Accuracy: 14.29%
Epoch 7/10, Train Loss: 1.7985, Train Accuracy: 21.43%
Val Loss: 2.0284, Val Accuracy: 14.29%
Epoch 8/10, Train Loss: 1.7191, Train Accuracy: 28.57%
Val Loss: 2.0044, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.6393, Train Accuracy: 32.14%
Val Loss: 1.9798, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.5588, Train Accuracy: 39.29%
Val Loss: 1.9548, Val Accuracy: 14.29%
Best validation accuracy for art_painting: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
art_painting adapter trained. Validation Accuracy: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.0397, Train Accuracy: 21.43%
Val Loss: 2.1441, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 1.9932, Train Accuracy: 21.43%
Val Loss: 2.1268, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 1.9456, Train Accuracy: 25.00%
Val Loss: 2.1093, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 1.8937, Train Accuracy: 28.57%
Val Loss: 2.0921, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 1.8496, Train Accuracy: 32.14%
Val Loss: 2.0762, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 1.7988, Train Accuracy: 35.71%
Val Loss: 2.0611, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 1.7511, Train Accuracy: 35.71%
Val Loss: 2.0455, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 1.7042, Train Accuracy: 39.29%
Val Loss: 2.0295, Val Accuracy: 28.57%
Epoch 9/10, Train Loss: 1.6539, Train Accuracy: 39.29%
Val Loss: 2.0131, Val Accuracy: 28.57%
Epoch 10/10, Train Loss: 1.6026, Train Accuracy: 46.43%
Val Loss: 1.9962, Val Accuracy: 28.57%
Best validation accuracy for photo: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
photo adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6139, Train Accuracy: 10.71%
Val Loss: 2.2562, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 2.4884, Train Accuracy: 14.29%
Val Loss: 2.2434, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 2.4203, Train Accuracy: 10.71%
Val Loss: 2.2349, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 2.3472, Train Accuracy: 10.71%
Val Loss: 2.2281, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 2.2680, Train Accuracy: 10.71%
Val Loss: 2.2254, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 2.1841, Train Accuracy: 10.71%
Val Loss: 2.2257, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 2.1067, Train Accuracy: 10.71%
Val Loss: 2.2230, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 2.0303, Train Accuracy: 10.71%
Val Loss: 2.2190, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.9541, Train Accuracy: 17.86%
Val Loss: 2.2149, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.8802, Train Accuracy: 17.86%
Val Loss: 2.2129, Val Accuracy: 0.00%
Warning: No best state found for domain cartoon. Using the final state.
Best validation accuracy for cartoon: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Evaluating individual LoRA adapters on the test domain:
Created LoRA model: <class 'peft.peft_model.PeftModel'>
art_painting adapter - Test Loss: 2.2703, Test Accuracy: 21.88%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
photo adapter - Test Loss: 2.2324, Test Accuracy: 21.88%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
cartoon adapter - Test Loss: 2.1003, Test Accuracy: 18.75%

Training coefficients for adapter merging
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Coefficient gradients: tensor([3.5297e-09, 3.5297e-09, 3.5297e-09], device='cuda:0')
Epoch 1, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.33276686 0.33233485 0.33489832]
Coefficient gradients: tensor([ 3.7361e-10, -2.7357e-09, -1.9499e-09], device='cuda:0')
Epoch 2, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.3060135  0.34897205 0.34501442]
Coefficient gradients: tensor([-1.0680e-09,  3.0897e-09,  2.2903e-09], device='cuda:0')
Epoch 3, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.31456223 0.34523386 0.34020394]
Coefficient gradients: tensor([ 9.5385e-10, -3.0080e-10,  2.4855e-09], device='cuda:0')
Epoch 4, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.32084373 0.3507653  0.328391  ]
Coefficient gradients: tensor([-3.7002e-09,  2.6400e-09,  1.0602e-09], device='cuda:0')
Epoch 5, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.3517368  0.33669955 0.31156364]
Coefficient gradients: tensor([ 2.9094e-10, -6.0122e-10,  3.1028e-10], device='cuda:0')
Epoch 6, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.37191188 0.32990983 0.2981783 ]
Coefficient gradients: tensor([-5.8684e-09,  2.1373e-09, -3.7195e-09], device='cuda:0')
Epoch 7, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.40990207 0.30075428 0.28934366]
Coefficient gradients: tensor([-7.0997e-09,  1.0816e-09, -1.4324e-09], device='cuda:0')
Epoch 8, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.4560787  0.26672173 0.27719954]
Coefficient gradients: tensor([-1.7820e-08, -4.6525e-09, -1.0468e-08], device='cuda:0')
Epoch 9, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.50944257 0.22028561 0.27027178]
Coefficient gradients: tensor([-1.2260e-08, -7.7670e-09, -1.0758e-08], device='cuda:0')
Epoch 10, Loss: 1.3612, Accuracy: 33.33%
Coefficients: [0.5555488  0.18431559 0.26013562]
Best coefficient accuracy: 33.33%
Final best coefficients: [0.33276686 0.33233485 0.33489832]

Merged model with TIES - Test Loss: 1.9162, Test Accuracy: 15.62%

Summary of All Runs:
Baseline Model Accuracy: 18.75% ± 0.00%
Merged Model Accuracy: 15.62% ± 0.00%
Average Coefficients:
  art_painting: 0.3328 ± 0.0000
  photo: 0.3323 ± 0.0000
  cartoon: 0.3349 ± 0.0000
