
--- Run 1/3 ---

Running LoRA with TIES experiment
Test domain: art_painting
Train domains: ['photo', 'cartoon', 'sketch']
Baseline Epoch 1/10, Train Loss: 1.0503, Train Accuracy: 66.67%
Val Loss: 2.4122, Val Accuracy: 12.50%
Baseline Epoch 2/10, Train Loss: 0.1508, Train Accuracy: 100.00%
Val Loss: 2.4754, Val Accuracy: 12.50%
Baseline Epoch 3/10, Train Loss: 0.0215, Train Accuracy: 100.00%
Val Loss: 2.5211, Val Accuracy: 12.50%
Baseline Epoch 4/10, Train Loss: 0.0054, Train Accuracy: 100.00%
Val Loss: 2.5760, Val Accuracy: 12.50%
Baseline Epoch 5/10, Train Loss: 0.0020, Train Accuracy: 100.00%
Val Loss: 2.6105, Val Accuracy: 12.50%
Baseline Epoch 6/10, Train Loss: 0.0010, Train Accuracy: 100.00%
Val Loss: 2.6502, Val Accuracy: 12.50%
Baseline Epoch 7/10, Train Loss: 0.0006, Train Accuracy: 100.00%
Val Loss: 2.7050, Val Accuracy: 12.50%
Baseline Epoch 8/10, Train Loss: 0.0004, Train Accuracy: 100.00%
Val Loss: 2.7604, Val Accuracy: 12.50%
Baseline Epoch 9/10, Train Loss: 0.0003, Train Accuracy: 100.00%
Val Loss: 2.8183, Val Accuracy: 12.50%
Baseline Epoch 10/10, Train Loss: 0.0002, Train Accuracy: 100.00%
Val Loss: 2.8527, Val Accuracy: 12.50%
Baseline Model - Final Test Accuracy: 12.50%

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 1.9158, Train Accuracy: 28.57%
Val Loss: 2.6368, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 1.8702, Train Accuracy: 28.57%
Val Loss: 2.6163, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 1.8225, Train Accuracy: 32.14%
Val Loss: 2.5949, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 1.7711, Train Accuracy: 35.71%
Val Loss: 2.5734, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 1.7235, Train Accuracy: 39.29%
Val Loss: 2.5544, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 1.6727, Train Accuracy: 39.29%
Val Loss: 2.5356, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 1.6239, Train Accuracy: 42.86%
Val Loss: 2.5160, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 1.5733, Train Accuracy: 42.86%
Val Loss: 2.4959, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.5223, Train Accuracy: 42.86%
Val Loss: 2.4758, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.4712, Train Accuracy: 46.43%
Val Loss: 2.4555, Val Accuracy: 0.00%
Warning: No best state found for domain photo. Using the final state.
Best validation accuracy for photo: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
photo adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6305, Train Accuracy: 7.14%
Val Loss: 2.0953, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.5277, Train Accuracy: 7.14%
Val Loss: 2.0542, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.4690, Train Accuracy: 3.57%
Val Loss: 2.0359, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 2.4032, Train Accuracy: 7.14%
Val Loss: 2.0294, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 2.3345, Train Accuracy: 7.14%
Val Loss: 2.0307, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 2.2612, Train Accuracy: 7.14%
Val Loss: 2.0400, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 2.1805, Train Accuracy: 10.71%
Val Loss: 2.0554, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 2.0982, Train Accuracy: 14.29%
Val Loss: 2.0744, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 2.0179, Train Accuracy: 14.29%
Val Loss: 2.0962, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.9425, Train Accuracy: 21.43%
Val Loss: 2.1145, Val Accuracy: 14.29%
Best validation accuracy for cartoon: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: sketch

Training LoRA adapter for domain: sketch
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2758, Train Accuracy: 32.14%
Val Loss: 2.0975, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 2.1733, Train Accuracy: 28.57%
Val Loss: 2.0564, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 2.0790, Train Accuracy: 25.00%
Val Loss: 2.0104, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 1.9908, Train Accuracy: 25.00%
Val Loss: 1.9691, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 1.9101, Train Accuracy: 25.00%
Val Loss: 1.9304, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 1.8410, Train Accuracy: 28.57%
Val Loss: 1.8942, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 1.7781, Train Accuracy: 28.57%
Val Loss: 1.8637, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 1.7192, Train Accuracy: 28.57%
Val Loss: 1.8382, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.6617, Train Accuracy: 35.71%
Val Loss: 1.8174, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.6093, Train Accuracy: 46.43%
Val Loss: 1.8020, Val Accuracy: 14.29%
Best validation accuracy for sketch: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
sketch adapter trained. Validation Accuracy: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Evaluating individual LoRA adapters on the test domain:
Created LoRA model: <class 'peft.peft_model.PeftModel'>
photo adapter - Test Loss: 2.2757, Test Accuracy: 12.50%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
cartoon adapter - Test Loss: 2.3110, Test Accuracy: 9.38%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
sketch adapter - Test Loss: 2.2966, Test Accuracy: 6.25%

Training coefficients for adapter merging
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 1, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.5178e-10, -4.5178e-10, -4.5178e-10], device='cuda:0')
Epoch 2, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 3, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 4, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.5178e-10, -4.5178e-10, -4.5178e-10], device='cuda:0')
Epoch 5, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.5178e-10, -4.5178e-10, -4.5178e-10], device='cuda:0')
Epoch 6, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 7, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 8, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 9, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([-4.5178e-10, -4.5178e-10, -4.5178e-10], device='cuda:0')
Epoch 10, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Best coefficient accuracy: 66.67%
Final best coefficients: [0.33333334 0.33333334 0.33333334]

Merged model with TIES - Test Loss: 1.9821, Test Accuracy: 3.12%

--- Run 2/3 ---

Running LoRA with TIES experiment
Test domain: art_painting
Train domains: ['photo', 'cartoon', 'sketch']
Baseline Epoch 1/10, Train Loss: 1.0503, Train Accuracy: 66.67%
Val Loss: 2.4122, Val Accuracy: 12.50%
Baseline Epoch 2/10, Train Loss: 0.1508, Train Accuracy: 100.00%
Val Loss: 2.4754, Val Accuracy: 12.50%
Baseline Epoch 3/10, Train Loss: 0.0215, Train Accuracy: 100.00%
Val Loss: 2.5211, Val Accuracy: 12.50%
Baseline Epoch 4/10, Train Loss: 0.0054, Train Accuracy: 100.00%
Val Loss: 2.5760, Val Accuracy: 12.50%
Baseline Epoch 5/10, Train Loss: 0.0020, Train Accuracy: 100.00%
Val Loss: 2.6105, Val Accuracy: 12.50%
Baseline Epoch 6/10, Train Loss: 0.0010, Train Accuracy: 100.00%
Val Loss: 2.6502, Val Accuracy: 12.50%
Baseline Epoch 7/10, Train Loss: 0.0006, Train Accuracy: 100.00%
Val Loss: 2.7050, Val Accuracy: 12.50%
Baseline Epoch 8/10, Train Loss: 0.0004, Train Accuracy: 100.00%
Val Loss: 2.7604, Val Accuracy: 12.50%
Baseline Epoch 9/10, Train Loss: 0.0003, Train Accuracy: 100.00%
Val Loss: 2.8183, Val Accuracy: 12.50%
Baseline Epoch 10/10, Train Loss: 0.0002, Train Accuracy: 100.00%
Val Loss: 2.8527, Val Accuracy: 12.50%
Baseline Model - Final Test Accuracy: 12.50%

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 1.9158, Train Accuracy: 28.57%
Val Loss: 2.6368, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 1.8702, Train Accuracy: 28.57%
Val Loss: 2.6163, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 1.8225, Train Accuracy: 32.14%
Val Loss: 2.5949, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 1.7711, Train Accuracy: 35.71%
Val Loss: 2.5734, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 1.7235, Train Accuracy: 39.29%
Val Loss: 2.5544, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 1.6727, Train Accuracy: 39.29%
Val Loss: 2.5356, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 1.6239, Train Accuracy: 42.86%
Val Loss: 2.5160, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 1.5733, Train Accuracy: 42.86%
Val Loss: 2.4959, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.5223, Train Accuracy: 42.86%
Val Loss: 2.4758, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.4712, Train Accuracy: 46.43%
Val Loss: 2.4555, Val Accuracy: 0.00%
Warning: No best state found for domain photo. Using the final state.
Best validation accuracy for photo: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
photo adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6305, Train Accuracy: 7.14%
Val Loss: 2.0953, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.5277, Train Accuracy: 7.14%
Val Loss: 2.0542, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.4690, Train Accuracy: 3.57%
Val Loss: 2.0359, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 2.4032, Train Accuracy: 7.14%
Val Loss: 2.0294, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 2.3345, Train Accuracy: 7.14%
Val Loss: 2.0307, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 2.2612, Train Accuracy: 7.14%
Val Loss: 2.0400, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 2.1805, Train Accuracy: 10.71%
Val Loss: 2.0554, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 2.0982, Train Accuracy: 14.29%
Val Loss: 2.0744, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 2.0179, Train Accuracy: 14.29%
Val Loss: 2.0962, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.9425, Train Accuracy: 21.43%
Val Loss: 2.1145, Val Accuracy: 14.29%
Best validation accuracy for cartoon: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: sketch

Training LoRA adapter for domain: sketch
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2758, Train Accuracy: 32.14%
Val Loss: 2.0975, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 2.1733, Train Accuracy: 28.57%
Val Loss: 2.0564, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 2.0790, Train Accuracy: 25.00%
Val Loss: 2.0104, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 1.9908, Train Accuracy: 25.00%
Val Loss: 1.9691, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 1.9101, Train Accuracy: 25.00%
Val Loss: 1.9304, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 1.8410, Train Accuracy: 28.57%
Val Loss: 1.8942, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 1.7781, Train Accuracy: 28.57%
Val Loss: 1.8637, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 1.7192, Train Accuracy: 28.57%
Val Loss: 1.8382, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.6617, Train Accuracy: 35.71%
Val Loss: 1.8174, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.6093, Train Accuracy: 46.43%
Val Loss: 1.8020, Val Accuracy: 14.29%
Best validation accuracy for sketch: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
sketch adapter trained. Validation Accuracy: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Evaluating individual LoRA adapters on the test domain:
Created LoRA model: <class 'peft.peft_model.PeftModel'>
photo adapter - Test Loss: 2.2757, Test Accuracy: 12.50%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
cartoon adapter - Test Loss: 2.3110, Test Accuracy: 9.38%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
sketch adapter - Test Loss: 2.2966, Test Accuracy: 6.25%

Training coefficients for adapter merging
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 1, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 2, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 3, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 4, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 5, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 6, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 7, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 8, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 9, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 10, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Best coefficient accuracy: 66.67%
Final best coefficients: [0.33333334 0.33333334 0.33333334]

Merged model with TIES - Test Loss: 1.9821, Test Accuracy: 3.12%

--- Run 3/3 ---

Running LoRA with TIES experiment
Test domain: art_painting
Train domains: ['photo', 'cartoon', 'sketch']
Baseline Epoch 1/10, Train Loss: 1.0503, Train Accuracy: 66.67%
Val Loss: 2.4122, Val Accuracy: 12.50%
Baseline Epoch 2/10, Train Loss: 0.1508, Train Accuracy: 100.00%
Val Loss: 2.4754, Val Accuracy: 12.50%
Baseline Epoch 3/10, Train Loss: 0.0215, Train Accuracy: 100.00%
Val Loss: 2.5211, Val Accuracy: 12.50%
Baseline Epoch 4/10, Train Loss: 0.0054, Train Accuracy: 100.00%
Val Loss: 2.5760, Val Accuracy: 12.50%
Baseline Epoch 5/10, Train Loss: 0.0020, Train Accuracy: 100.00%
Val Loss: 2.6105, Val Accuracy: 12.50%
Baseline Epoch 6/10, Train Loss: 0.0010, Train Accuracy: 100.00%
Val Loss: 2.6502, Val Accuracy: 12.50%
Baseline Epoch 7/10, Train Loss: 0.0006, Train Accuracy: 100.00%
Val Loss: 2.7050, Val Accuracy: 12.50%
Baseline Epoch 8/10, Train Loss: 0.0004, Train Accuracy: 100.00%
Val Loss: 2.7604, Val Accuracy: 12.50%
Baseline Epoch 9/10, Train Loss: 0.0003, Train Accuracy: 100.00%
Val Loss: 2.8183, Val Accuracy: 12.50%
Baseline Epoch 10/10, Train Loss: 0.0002, Train Accuracy: 100.00%
Val Loss: 2.8527, Val Accuracy: 12.50%
Baseline Model - Final Test Accuracy: 12.50%

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 1.9158, Train Accuracy: 28.57%
Val Loss: 2.6368, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 1.8702, Train Accuracy: 28.57%
Val Loss: 2.6163, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 1.8225, Train Accuracy: 32.14%
Val Loss: 2.5949, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 1.7711, Train Accuracy: 35.71%
Val Loss: 2.5734, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 1.7235, Train Accuracy: 39.29%
Val Loss: 2.5544, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 1.6727, Train Accuracy: 39.29%
Val Loss: 2.5356, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 1.6239, Train Accuracy: 42.86%
Val Loss: 2.5160, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 1.5734, Train Accuracy: 42.86%
Val Loss: 2.4959, Val Accuracy: 0.00%
Epoch 9/10, Train Loss: 1.5223, Train Accuracy: 42.86%
Val Loss: 2.4758, Val Accuracy: 0.00%
Epoch 10/10, Train Loss: 1.4712, Train Accuracy: 46.43%
Val Loss: 2.4555, Val Accuracy: 0.00%
Warning: No best state found for domain photo. Using the final state.
Best validation accuracy for photo: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
photo adapter trained. Validation Accuracy: 0.00%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.6305, Train Accuracy: 7.14%
Val Loss: 2.0953, Val Accuracy: 28.57%
Epoch 2/10, Train Loss: 2.5277, Train Accuracy: 7.14%
Val Loss: 2.0542, Val Accuracy: 28.57%
Epoch 3/10, Train Loss: 2.4690, Train Accuracy: 3.57%
Val Loss: 2.0359, Val Accuracy: 28.57%
Epoch 4/10, Train Loss: 2.4032, Train Accuracy: 7.14%
Val Loss: 2.0294, Val Accuracy: 28.57%
Epoch 5/10, Train Loss: 2.3345, Train Accuracy: 7.14%
Val Loss: 2.0307, Val Accuracy: 28.57%
Epoch 6/10, Train Loss: 2.2612, Train Accuracy: 7.14%
Val Loss: 2.0400, Val Accuracy: 28.57%
Epoch 7/10, Train Loss: 2.1805, Train Accuracy: 10.71%
Val Loss: 2.0554, Val Accuracy: 28.57%
Epoch 8/10, Train Loss: 2.0982, Train Accuracy: 14.29%
Val Loss: 2.0744, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 2.0179, Train Accuracy: 14.29%
Val Loss: 2.0962, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.9425, Train Accuracy: 21.43%
Val Loss: 2.1145, Val Accuracy: 14.29%
Best validation accuracy for cartoon: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
cartoon adapter trained. Validation Accuracy: 28.57%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: sketch

Training LoRA adapter for domain: sketch
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2758, Train Accuracy: 32.14%
Val Loss: 2.0975, Val Accuracy: 0.00%
Epoch 2/10, Train Loss: 2.1733, Train Accuracy: 28.57%
Val Loss: 2.0564, Val Accuracy: 0.00%
Epoch 3/10, Train Loss: 2.0790, Train Accuracy: 25.00%
Val Loss: 2.0104, Val Accuracy: 0.00%
Epoch 4/10, Train Loss: 1.9908, Train Accuracy: 25.00%
Val Loss: 1.9691, Val Accuracy: 0.00%
Epoch 5/10, Train Loss: 1.9101, Train Accuracy: 25.00%
Val Loss: 1.9304, Val Accuracy: 0.00%
Epoch 6/10, Train Loss: 1.8410, Train Accuracy: 28.57%
Val Loss: 1.8942, Val Accuracy: 0.00%
Epoch 7/10, Train Loss: 1.7781, Train Accuracy: 28.57%
Val Loss: 1.8637, Val Accuracy: 0.00%
Epoch 8/10, Train Loss: 1.7192, Train Accuracy: 28.57%
Val Loss: 1.8382, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.6617, Train Accuracy: 35.71%
Val Loss: 1.8174, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.6093, Train Accuracy: 46.43%
Val Loss: 1.8020, Val Accuracy: 14.29%
Best validation accuracy for sketch: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])
sketch adapter trained. Validation Accuracy: 14.29%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Evaluating individual LoRA adapters on the test domain:
Created LoRA model: <class 'peft.peft_model.PeftModel'>
photo adapter - Test Loss: 2.2757, Test Accuracy: 12.50%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
cartoon adapter - Test Loss: 2.3110, Test Accuracy: 9.38%
Created LoRA model: <class 'peft.peft_model.PeftModel'>
sketch adapter - Test Loss: 2.2966, Test Accuracy: 6.25%

Training coefficients for adapter merging
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 1, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 2, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 3, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 4, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 5, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 6, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 7, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 8, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([9.4823e-09, 9.4823e-09, 9.4823e-09], device='cuda:0')
Epoch 9, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Coefficient gradients: tensor([4.5153e-09, 4.5153e-09, 4.5153e-09], device='cuda:0')
Epoch 10, Loss: 1.0969, Accuracy: 66.67%
Coefficients: [0.33333334 0.33333334 0.33333334]
Best coefficient accuracy: 66.67%
Final best coefficients: [0.33333334 0.33333334 0.33333334]

Merged model with TIES - Test Loss: 1.9821, Test Accuracy: 3.12%

Summary of All Runs:
Baseline Model Accuracy: 12.50% ± 0.00%
Merged Model Accuracy: 3.12% ± 0.00%
Average Coefficients:
  photo: 0.3333 ± 0.0000
  cartoon: 0.3333 ± 0.0000
  sketch: 0.3333 ± 0.0000
