
--- Run 1/3 ---

Running LoRA with TIES experiment
Test domain: sketch
Train domains: ['photo', 'art_painting', 'cartoon']
Baseline Epoch 1/10, Train Loss: 1.2848, Train Accuracy: 57.14%
Val Loss: 2.7779, Val Accuracy: 11.11%
Baseline Epoch 2/10, Train Loss: 0.9273, Train Accuracy: 57.14%
Val Loss: 2.6904, Val Accuracy: 15.87%
Baseline Epoch 3/10, Train Loss: 0.4330, Train Accuracy: 100.00%
Val Loss: 2.7110, Val Accuracy: 15.87%
Baseline Epoch 4/10, Train Loss: 0.2745, Train Accuracy: 100.00%
Val Loss: 2.7965, Val Accuracy: 19.05%
Baseline Epoch 5/10, Train Loss: 0.1389, Train Accuracy: 100.00%
Val Loss: 2.9282, Val Accuracy: 17.46%
Baseline Epoch 6/10, Train Loss: 0.0680, Train Accuracy: 100.00%
Val Loss: 3.0900, Val Accuracy: 14.29%
Baseline Epoch 7/10, Train Loss: 0.0365, Train Accuracy: 100.00%
Val Loss: 3.2614, Val Accuracy: 12.70%
Baseline Epoch 8/10, Train Loss: 0.0208, Train Accuracy: 100.00%
Val Loss: 3.4243, Val Accuracy: 12.70%
Baseline Epoch 9/10, Train Loss: 0.0127, Train Accuracy: 100.00%
Val Loss: 3.5705, Val Accuracy: 12.70%
Baseline Epoch 10/10, Train Loss: 0.0082, Train Accuracy: 100.00%
Val Loss: 3.7008, Val Accuracy: 12.70%
Baseline Model - Final Test Accuracy: 12.70%

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.1961, Train Accuracy: 14.29%
Val Loss: 2.0955, Val Accuracy: 35.71%
Epoch 2/10, Train Loss: 2.1405, Train Accuracy: 16.07%
Val Loss: 2.0558, Val Accuracy: 35.71%
Epoch 3/10, Train Loss: 2.0485, Train Accuracy: 16.07%
Val Loss: 2.0231, Val Accuracy: 35.71%
Epoch 4/10, Train Loss: 1.9722, Train Accuracy: 19.64%
Val Loss: 1.9884, Val Accuracy: 35.71%
Epoch 5/10, Train Loss: 1.9221, Train Accuracy: 23.21%
Val Loss: 1.9554, Val Accuracy: 35.71%
Epoch 6/10, Train Loss: 1.8382, Train Accuracy: 28.57%
Val Loss: 1.9200, Val Accuracy: 35.71%
Epoch 7/10, Train Loss: 1.7659, Train Accuracy: 32.14%
Val Loss: 1.8706, Val Accuracy: 35.71%
Epoch 8/10, Train Loss: 1.6722, Train Accuracy: 41.07%
Val Loss: 1.8285, Val Accuracy: 35.71%
Epoch 9/10, Train Loss: 1.5991, Train Accuracy: 44.64%
Val Loss: 1.7870, Val Accuracy: 35.71%
Epoch 10/10, Train Loss: 1.5135, Train Accuracy: 44.64%
Val Loss: 1.7494, Val Accuracy: 35.71%
photo adapter trained. Validation Accuracy: 35.71%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2313, Train Accuracy: 16.07%
Val Loss: 2.2683, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1256, Train Accuracy: 19.64%
Val Loss: 2.2457, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 1.9984, Train Accuracy: 21.43%
Val Loss: 2.2382, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 1.9210, Train Accuracy: 25.00%
Val Loss: 2.2313, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.8229, Train Accuracy: 32.14%
Val Loss: 2.2073, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.7068, Train Accuracy: 35.71%
Val Loss: 2.1806, Val Accuracy: 21.43%
Epoch 7/10, Train Loss: 1.6255, Train Accuracy: 41.07%
Val Loss: 2.1525, Val Accuracy: 21.43%
Epoch 8/10, Train Loss: 1.5155, Train Accuracy: 46.43%
Val Loss: 2.1267, Val Accuracy: 21.43%
Epoch 9/10, Train Loss: 1.4203, Train Accuracy: 51.79%
Val Loss: 2.1134, Val Accuracy: 21.43%
Epoch 10/10, Train Loss: 1.3357, Train Accuracy: 57.14%
Val Loss: 2.1345, Val Accuracy: 21.43%
art_painting adapter trained. Validation Accuracy: 21.43%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.3031, Train Accuracy: 10.71%
Val Loss: 2.6202, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1726, Train Accuracy: 10.71%
Val Loss: 2.4887, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 2.0891, Train Accuracy: 12.50%
Val Loss: 2.4146, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 2.0090, Train Accuracy: 14.29%
Val Loss: 2.3641, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.9036, Train Accuracy: 16.07%
Val Loss: 2.3124, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.8145, Train Accuracy: 17.86%
Val Loss: 2.2619, Val Accuracy: 14.29%
Epoch 7/10, Train Loss: 1.7588, Train Accuracy: 23.21%
Val Loss: 2.2144, Val Accuracy: 14.29%
Epoch 8/10, Train Loss: 1.6672, Train Accuracy: 33.93%
Val Loss: 2.1687, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.5799, Train Accuracy: 39.29%
Val Loss: 2.1280, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.5008, Train Accuracy: 44.64%
Val Loss: 2.0868, Val Accuracy: 21.43%
cartoon adapter trained. Validation Accuracy: 21.43%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Training coefficients for adapter merging
Number of LoRA adapters: 3
Creating LoRA model for photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Setting weights for photo
Creating LoRA model for art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Setting weights for art_painting
Creating LoRA model for cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Setting weights for cartoon
Number of LoRA models created: 3
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 1, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 2, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 3, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 4, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 5, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 6, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 7, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 8, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 9, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 10, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Best coefficient accuracy: 42.86%
Final best coefficients: [0.33333334 0.33333334 0.33333334]

Merged model with TIES - Test Loss: 1.9156, Test Accuracy: 15.87%

--- Run 2/3 ---

Running LoRA with TIES experiment
Test domain: sketch
Train domains: ['photo', 'art_painting', 'cartoon']
Baseline Epoch 1/10, Train Loss: 1.2848, Train Accuracy: 57.14%
Val Loss: 2.7779, Val Accuracy: 11.11%
Baseline Epoch 2/10, Train Loss: 0.9273, Train Accuracy: 57.14%
Val Loss: 2.6904, Val Accuracy: 15.87%
Baseline Epoch 3/10, Train Loss: 0.4330, Train Accuracy: 100.00%
Val Loss: 2.7110, Val Accuracy: 15.87%
Baseline Epoch 4/10, Train Loss: 0.2745, Train Accuracy: 100.00%
Val Loss: 2.7965, Val Accuracy: 19.05%
Baseline Epoch 5/10, Train Loss: 0.1389, Train Accuracy: 100.00%
Val Loss: 2.9282, Val Accuracy: 17.46%
Baseline Epoch 6/10, Train Loss: 0.0680, Train Accuracy: 100.00%
Val Loss: 3.0900, Val Accuracy: 14.29%
Baseline Epoch 7/10, Train Loss: 0.0365, Train Accuracy: 100.00%
Val Loss: 3.2614, Val Accuracy: 12.70%
Baseline Epoch 8/10, Train Loss: 0.0208, Train Accuracy: 100.00%
Val Loss: 3.4243, Val Accuracy: 12.70%
Baseline Epoch 9/10, Train Loss: 0.0127, Train Accuracy: 100.00%
Val Loss: 3.5705, Val Accuracy: 12.70%
Baseline Epoch 10/10, Train Loss: 0.0082, Train Accuracy: 100.00%
Val Loss: 3.7008, Val Accuracy: 12.70%
Baseline Model - Final Test Accuracy: 12.70%

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.1961, Train Accuracy: 14.29%
Val Loss: 2.0955, Val Accuracy: 35.71%
Epoch 2/10, Train Loss: 2.1405, Train Accuracy: 16.07%
Val Loss: 2.0558, Val Accuracy: 35.71%
Epoch 3/10, Train Loss: 2.0485, Train Accuracy: 16.07%
Val Loss: 2.0231, Val Accuracy: 35.71%
Epoch 4/10, Train Loss: 1.9722, Train Accuracy: 19.64%
Val Loss: 1.9884, Val Accuracy: 35.71%
Epoch 5/10, Train Loss: 1.9221, Train Accuracy: 23.21%
Val Loss: 1.9554, Val Accuracy: 35.71%
Epoch 6/10, Train Loss: 1.8382, Train Accuracy: 28.57%
Val Loss: 1.9200, Val Accuracy: 35.71%
Epoch 7/10, Train Loss: 1.7659, Train Accuracy: 32.14%
Val Loss: 1.8705, Val Accuracy: 35.71%
Epoch 8/10, Train Loss: 1.6722, Train Accuracy: 41.07%
Val Loss: 1.8286, Val Accuracy: 35.71%
Epoch 9/10, Train Loss: 1.5991, Train Accuracy: 44.64%
Val Loss: 1.7872, Val Accuracy: 35.71%
Epoch 10/10, Train Loss: 1.5135, Train Accuracy: 44.64%
Val Loss: 1.7496, Val Accuracy: 35.71%
photo adapter trained. Validation Accuracy: 35.71%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2313, Train Accuracy: 16.07%
Val Loss: 2.2683, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1256, Train Accuracy: 19.64%
Val Loss: 2.2457, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 1.9984, Train Accuracy: 21.43%
Val Loss: 2.2382, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 1.9210, Train Accuracy: 25.00%
Val Loss: 2.2313, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.8229, Train Accuracy: 32.14%
Val Loss: 2.2073, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.7068, Train Accuracy: 35.71%
Val Loss: 2.1806, Val Accuracy: 21.43%
Epoch 7/10, Train Loss: 1.6255, Train Accuracy: 41.07%
Val Loss: 2.1525, Val Accuracy: 21.43%
Epoch 8/10, Train Loss: 1.5155, Train Accuracy: 46.43%
Val Loss: 2.1267, Val Accuracy: 21.43%
Epoch 9/10, Train Loss: 1.4203, Train Accuracy: 51.79%
Val Loss: 2.1134, Val Accuracy: 21.43%
Epoch 10/10, Train Loss: 1.3357, Train Accuracy: 57.14%
Val Loss: 2.1344, Val Accuracy: 21.43%
art_painting adapter trained. Validation Accuracy: 21.43%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.3031, Train Accuracy: 10.71%
Val Loss: 2.6202, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1726, Train Accuracy: 10.71%
Val Loss: 2.4887, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 2.0891, Train Accuracy: 12.50%
Val Loss: 2.4146, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 2.0090, Train Accuracy: 14.29%
Val Loss: 2.3641, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.9036, Train Accuracy: 16.07%
Val Loss: 2.3124, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.8145, Train Accuracy: 17.86%
Val Loss: 2.2619, Val Accuracy: 14.29%
Epoch 7/10, Train Loss: 1.7588, Train Accuracy: 23.21%
Val Loss: 2.2144, Val Accuracy: 14.29%
Epoch 8/10, Train Loss: 1.6672, Train Accuracy: 33.93%
Val Loss: 2.1687, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.5799, Train Accuracy: 39.29%
Val Loss: 2.1280, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.5008, Train Accuracy: 44.64%
Val Loss: 2.0868, Val Accuracy: 21.43%
cartoon adapter trained. Validation Accuracy: 21.43%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Training coefficients for adapter merging
Number of LoRA adapters: 3
Creating LoRA model for photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Setting weights for photo
Creating LoRA model for art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Setting weights for art_painting
Creating LoRA model for cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Setting weights for cartoon
Number of LoRA models created: 3
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 1, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 2, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 3, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 4, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 5, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 6, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 7, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 8, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 9, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 10, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Best coefficient accuracy: 42.86%
Final best coefficients: [0.33333334 0.33333334 0.33333334]

Merged model with TIES - Test Loss: 1.9156, Test Accuracy: 15.87%

--- Run 3/3 ---

Running LoRA with TIES experiment
Test domain: sketch
Train domains: ['photo', 'art_painting', 'cartoon']
Baseline Epoch 1/10, Train Loss: 1.2848, Train Accuracy: 57.14%
Val Loss: 2.7779, Val Accuracy: 11.11%
Baseline Epoch 2/10, Train Loss: 0.9273, Train Accuracy: 57.14%
Val Loss: 2.6904, Val Accuracy: 15.87%
Baseline Epoch 3/10, Train Loss: 0.4330, Train Accuracy: 100.00%
Val Loss: 2.7110, Val Accuracy: 15.87%
Baseline Epoch 4/10, Train Loss: 0.2745, Train Accuracy: 100.00%
Val Loss: 2.7965, Val Accuracy: 19.05%
Baseline Epoch 5/10, Train Loss: 0.1389, Train Accuracy: 100.00%
Val Loss: 2.9282, Val Accuracy: 17.46%
Baseline Epoch 6/10, Train Loss: 0.0680, Train Accuracy: 100.00%
Val Loss: 3.0900, Val Accuracy: 14.29%
Baseline Epoch 7/10, Train Loss: 0.0365, Train Accuracy: 100.00%
Val Loss: 3.2614, Val Accuracy: 12.70%
Baseline Epoch 8/10, Train Loss: 0.0208, Train Accuracy: 100.00%
Val Loss: 3.4243, Val Accuracy: 12.70%
Baseline Epoch 9/10, Train Loss: 0.0127, Train Accuracy: 100.00%
Val Loss: 3.5705, Val Accuracy: 12.70%
Baseline Epoch 10/10, Train Loss: 0.0082, Train Accuracy: 100.00%
Val Loss: 3.7008, Val Accuracy: 12.70%
Baseline Model - Final Test Accuracy: 12.70%

Training LoRA adapter for domain: photo

Training LoRA adapter for domain: photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.1961, Train Accuracy: 14.29%
Val Loss: 2.0955, Val Accuracy: 35.71%
Epoch 2/10, Train Loss: 2.1405, Train Accuracy: 16.07%
Val Loss: 2.0558, Val Accuracy: 35.71%
Epoch 3/10, Train Loss: 2.0485, Train Accuracy: 16.07%
Val Loss: 2.0231, Val Accuracy: 35.71%
Epoch 4/10, Train Loss: 1.9722, Train Accuracy: 19.64%
Val Loss: 1.9884, Val Accuracy: 35.71%
Epoch 5/10, Train Loss: 1.9221, Train Accuracy: 23.21%
Val Loss: 1.9554, Val Accuracy: 35.71%
Epoch 6/10, Train Loss: 1.8382, Train Accuracy: 28.57%
Val Loss: 1.9200, Val Accuracy: 35.71%
Epoch 7/10, Train Loss: 1.7659, Train Accuracy: 32.14%
Val Loss: 1.8705, Val Accuracy: 35.71%
Epoch 8/10, Train Loss: 1.6722, Train Accuracy: 41.07%
Val Loss: 1.8286, Val Accuracy: 35.71%
Epoch 9/10, Train Loss: 1.5991, Train Accuracy: 44.64%
Val Loss: 1.7873, Val Accuracy: 35.71%
Epoch 10/10, Train Loss: 1.5135, Train Accuracy: 44.64%
Val Loss: 1.7496, Val Accuracy: 35.71%
photo adapter trained. Validation Accuracy: 35.71%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: art_painting

Training LoRA adapter for domain: art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.2313, Train Accuracy: 16.07%
Val Loss: 2.2683, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1256, Train Accuracy: 19.64%
Val Loss: 2.2457, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 1.9984, Train Accuracy: 21.43%
Val Loss: 2.2382, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 1.9210, Train Accuracy: 25.00%
Val Loss: 2.2313, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.8229, Train Accuracy: 32.14%
Val Loss: 2.2073, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.7068, Train Accuracy: 35.71%
Val Loss: 2.1806, Val Accuracy: 21.43%
Epoch 7/10, Train Loss: 1.6255, Train Accuracy: 41.07%
Val Loss: 2.1525, Val Accuracy: 21.43%
Epoch 8/10, Train Loss: 1.5155, Train Accuracy: 46.43%
Val Loss: 2.1267, Val Accuracy: 21.43%
Epoch 9/10, Train Loss: 1.4203, Train Accuracy: 51.79%
Val Loss: 2.1134, Val Accuracy: 21.43%
Epoch 10/10, Train Loss: 1.3357, Train Accuracy: 57.14%
Val Loss: 2.1345, Val Accuracy: 21.43%
art_painting adapter trained. Validation Accuracy: 21.43%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Training LoRA adapter for domain: cartoon

Training LoRA adapter for domain: cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Epoch 1/10, Train Loss: 2.3031, Train Accuracy: 10.71%
Val Loss: 2.6202, Val Accuracy: 14.29%
Epoch 2/10, Train Loss: 2.1726, Train Accuracy: 10.71%
Val Loss: 2.4887, Val Accuracy: 14.29%
Epoch 3/10, Train Loss: 2.0891, Train Accuracy: 12.50%
Val Loss: 2.4146, Val Accuracy: 14.29%
Epoch 4/10, Train Loss: 2.0090, Train Accuracy: 14.29%
Val Loss: 2.3641, Val Accuracy: 14.29%
Epoch 5/10, Train Loss: 1.9036, Train Accuracy: 16.07%
Val Loss: 2.3124, Val Accuracy: 14.29%
Epoch 6/10, Train Loss: 1.8145, Train Accuracy: 17.86%
Val Loss: 2.2619, Val Accuracy: 14.29%
Epoch 7/10, Train Loss: 1.7588, Train Accuracy: 23.21%
Val Loss: 2.2144, Val Accuracy: 14.29%
Epoch 8/10, Train Loss: 1.6672, Train Accuracy: 33.93%
Val Loss: 2.1687, Val Accuracy: 14.29%
Epoch 9/10, Train Loss: 1.5799, Train Accuracy: 39.29%
Val Loss: 2.1280, Val Accuracy: 14.29%
Epoch 10/10, Train Loss: 1.5008, Train Accuracy: 44.64%
Val Loss: 2.0868, Val Accuracy: 21.43%
cartoon adapter trained. Validation Accuracy: 21.43%
LoRA state keys: dict_keys(['base_model.model.blocks.0.attn.qkv.lora_A.weight', 'base_model.model.blocks.0.attn.qkv.lora_B.weight', 'base_model.model.blocks.1.attn.qkv.lora_A.weight', 'base_model.model.blocks.1.attn.qkv.lora_B.weight', 'base_model.model.blocks.2.attn.qkv.lora_A.weight', 'base_model.model.blocks.2.attn.qkv.lora_B.weight', 'base_model.model.blocks.3.attn.qkv.lora_A.weight', 'base_model.model.blocks.3.attn.qkv.lora_B.weight', 'base_model.model.blocks.4.attn.qkv.lora_A.weight', 'base_model.model.blocks.4.attn.qkv.lora_B.weight', 'base_model.model.blocks.5.attn.qkv.lora_A.weight', 'base_model.model.blocks.5.attn.qkv.lora_B.weight', 'base_model.model.blocks.6.attn.qkv.lora_A.weight', 'base_model.model.blocks.6.attn.qkv.lora_B.weight', 'base_model.model.blocks.7.attn.qkv.lora_A.weight', 'base_model.model.blocks.7.attn.qkv.lora_B.weight', 'base_model.model.blocks.8.attn.qkv.lora_A.weight', 'base_model.model.blocks.8.attn.qkv.lora_B.weight', 'base_model.model.blocks.9.attn.qkv.lora_A.weight', 'base_model.model.blocks.9.attn.qkv.lora_B.weight', 'base_model.model.blocks.10.attn.qkv.lora_A.weight', 'base_model.model.blocks.10.attn.qkv.lora_B.weight', 'base_model.model.blocks.11.attn.qkv.lora_A.weight', 'base_model.model.blocks.11.attn.qkv.lora_B.weight'])

Number of trained LoRA adapters: 3

Training coefficients for adapter merging
Number of LoRA adapters: 3
Creating LoRA model for photo
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Setting weights for photo
Creating LoRA model for art_painting
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Setting weights for art_painting
Creating LoRA model for cartoon
Created LoRA model: <class 'peft.peft_model.PeftModel'>
Setting weights for cartoon
Number of LoRA models created: 3
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 1, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 2, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 3, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 4, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 5, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 6, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 7, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 8, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 9, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Input shape: torch.Size([7, 3, 224, 224])
Target shape: torch.Size([7])
Processing model 0: photo
Model 0 (photo) output shape: torch.Size([7, 7])
Processing model 1: art_painting
Model 1 (art_painting) output shape: torch.Size([7, 7])
Processing model 2: cartoon
Model 2 (cartoon) output shape: torch.Size([7, 7])
Number of model outputs: 3
Weighted outputs shape: torch.Size([3, 7, 7])
Final outputs shape: torch.Size([7, 7])
Epoch 10, Loss: 1.3574, Accuracy: 42.86%
Coefficients: [0.33333334 0.33333334 0.33333334]
Best coefficient accuracy: 42.86%
Final best coefficients: [0.33333334 0.33333334 0.33333334]

Merged model with TIES - Test Loss: 1.9156, Test Accuracy: 15.87%

Summary of All Runs:
Baseline Model Accuracy: 12.70% ± 0.00%
Merged Model Accuracy: 15.87% ± 0.00%
Average Coefficients:
  photo: 0.3333 ± 0.0000
  art_painting: 0.3333 ± 0.0000
  cartoon: 0.3333 ± 0.0000
